<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Fetching a CSV File from a URL and Loading it into a Spark DataFrame</title>
  <style>
    body {
      font-family: Arial, sans-serif;
      background-color: #f4f4f9;
      color: #333;
      margin: 0;
      padding: 0;
    }
    header {
      background-color: #007acc;
      color: white;
      text-align: center;
      padding: 20px;
    }
    .container {
      width: 80%;
      margin: 20px auto;
    }
    h1, h2 {
      color: #333;
    }
    pre {
      background-color: #2d2d2d;
      color: #f8f8f2;
      padding: 20px;
      border-radius: 5px;
      overflow-x: auto;
    }
    code {
      color: #ff79c6;
    }
    .section {
      margin-bottom: 40px;
    }
    .img-container {
      text-align: center;
    }
    .img-container img {
      max-width: 100%;
      height: auto;
      border-radius: 10px;
      margin-bottom: 20px;
    }
    footer {
      background-color: #2d2d2d;
      color: white;
      text-align: center;
      padding: 10px;
      position: fixed;
      bottom: 0;
      width: 100%;
    }
  </style>
</head>
<body>

  <header>
    <h1>Fetching a CSV File from a URL and Loading it into a Spark DataFrame</h1>
  </header>

  <div class="container">

    <section class="section">
      <h2>Overview</h2>
      <p>I wanted to fetch a CSV file from a URL, process it, and load it into a Spark DataFrame for data analysis. To achieve this, I used Apache Spark and Scala.</p>
      <p>First, I imported the necessary libraries:</p>
      <ul>
        <li><strong>IOUtils</strong> from Apache Commons IO to read the content from the URL.</li>
        <li><strong>URL</strong> from Java to represent the CSV file’s URL.</li>
        <li><strong>SparkSession</strong> from Apache Spark to initialize a Spark session and work with the DataFrame.</li>
        <li><strong>Files and Paths</strong> from Java to handle file operations.</li>
      </ul>
      <p>Then, I created an object called <code>CSVFromURLToDataFrame</code> and defined the main method. Inside the main method:</p>
      <ul>
        <li>Initialized a Spark session using <code>SparkSession.builder()</code>.</li>
        <li>Defined the URL pointing to the CSV file hosted online.</li>
        <li>Used <code>IOUtils.toString()</code> to fetch the CSV content from the URL as a string.</li>
        <li>Saved this CSV content to a temporary local file using <code>Files.write()</code>.</li>
        <li>Read the CSV file into a DataFrame using Spark’s <code>.csv()</code> method, applying options like <code>header=true</code> (to treat the first row as column names) and <code>inferSchema=true</code> (to let Spark automatically infer the column data types).</li>
        <li>Displayed the DataFrame using <code>.show()</code> to see its contents.</li>
        <li>Finally, stopped the Spark session with <code>spark.stop()</code> to clean up resources.</li>
      </ul>
      <p>This process allowed me to easily fetch, process, and analyze the CSV data using Apache Spark and Scala.</p>
    </section>

    <section class="section">
      <h2>Code Example</h2>
      <pre><code>
import org.apache.commons.io.IOUtils
import java.net.URL
import org.apache.spark.sql.{SparkSession}
import java.nio.file.{Files, Paths}

object CSVFromURLToDataFrame {
  def main(args: Array[String]): Unit = {
    // Initialize SparkSession
    val spark = SparkSession.builder()
      .appName("CSV from URL to DataFrame")
      .master("local[*]")  // Local mode, change to your cluster settings if running on a cluster
      .getOrCreate()

    // Define the URL for the CSV file
    val urlfile = new URL("https://people.sc.fsu.edu/~jburkardt/data/csv/airtravel.csv")

    // Fetch the CSV content from the URL as a string
    val csvContent = IOUtils.toString(urlfile, "UTF-8")

    // Save the CSV content to a temporary file
    val tempFilePath = "/tmp/airtravel.csv"  // You can choose any valid path here
    Files.write(Paths.get(tempFilePath), csvContent.getBytes("UTF-8"))

    // Read the CSV file into a DataFrame using Spark
    val testcsv = spark
      .read
      .option("header", "true")   // CSV file has a header
      .option("inferSchema", "true") // Auto infer column data types
      .csv(tempFilePath)

    // Show the DataFrame (first 20 rows by default)
    testcsv.show()

    // Stop SparkSession
    spark.stop()
  }
}
      </code></pre>
    </section>

    <section class="section">
      <h2>Screenshots</h2>
      <p>Below are screenshots showing the code execution in the terminal:</p>
      <div class="img-container">
        <img src="https://raw.githubusercontent.com/nbahador/nbahador.github.io/main/assets/img/spark15.png" alt="Spark Execution 1">
        <img src="https://raw.githubusercontent.com/nbahador/nbahador.github.io/main/assets/img/spark16.png" alt="Spark Execution 2">
      </div>
    </section>

  </div>

  <footer>
    <p>&copy; 2025 Data Analysis with Apache Spark and Scala</p>
  </footer>

</body>
</html>
